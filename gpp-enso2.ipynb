{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "43fd52b8-c6f2-435b-a931-a2aee5a045e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "print(\"ok\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993d32da-ddb1-4926-8b00-f1ef09773adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "简化版：读取 NetCDF 文件并输出 lat/lon/time 基本信息\n",
    "- 使用 xarray 新写法：decode_times=CFDatetimeCoder(use_cftime=True)\n",
    "- 更稳健的坐标识别（兼容 lat/lon/latitude/longitude/nav_lat/nav_lon 等）\n",
    "- 统一字符串化时间，兼容 numpy.datetime64 与 cftime 对象\n",
    "- 使用 with 上下文自动关闭文件句柄\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "\n",
    "# ========== 用户可改区域 ==========\n",
    "# 文件目录\n",
    "DATA_DIR = Path(r\"D:\\cangku\\data\")\n",
    "\n",
    "# 目标文件列表\n",
    "FILES = [\n",
    "    \"gpp_CanESM5_abrupt-4xCO2_185001-194912_1x1.nc\",\n",
    "    \"gpp_Lmon_CanESM5_abrupt-4xCO2_185001-200012.nc\",\n",
    "    \"gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    \"gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    \"tos_Omon_CanESM5_abrupt-4xCO2_185001-200012.nc\",\n",
    "    \"tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    \"tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc\",\n",
    "]\n",
    "# =================================\n",
    "\n",
    "def _format_time_value(v) -> str:\n",
    "    \"\"\"将时间值安全地转为字符串，兼容 cftime 与 numpy.datetime64。\"\"\"\n",
    "    try:\n",
    "        return str(v)\n",
    "    except Exception:\n",
    "        try:\n",
    "            # 某些 cftime 对象可以 .isoformat()\n",
    "            return v.isoformat()\n",
    "        except Exception:\n",
    "            return repr(v)\n",
    "\n",
    "def _first_last_as_str(da) -> str:\n",
    "    \"\"\"将时间坐标的首尾值格式化为 'first → last'。\"\"\"\n",
    "    if da.size == 0:\n",
    "        return \"(empty)\"\n",
    "    first = _format_time_value(da.values[0])\n",
    "    last = _format_time_value(da.values[-1])\n",
    "    return f\"{first} → {last}\"\n",
    "\n",
    "def _find_coord_name(ds: xr.Dataset, candidates) -> str | None:\n",
    "    \"\"\"\n",
    "    在 ds.coords 中优先匹配候选名；若找不到，再到数据变量中用 attrs 判断。\n",
    "    返回匹配到的名字或 None。\n",
    "    \"\"\"\n",
    "    # 1) 直接在坐标名里找\n",
    "    lower_map = {name.lower(): name for name in ds.coords}\n",
    "    for cand in candidates:\n",
    "        if cand in lower_map:\n",
    "            return lower_map[cand]\n",
    "\n",
    "    # 2) 有些文件把经纬度放到 data_vars，尝试通过 attributes 判断\n",
    "    for var in list(ds.coords) + list(ds.data_vars):\n",
    "        v = ds[var]\n",
    "        std = (v.attrs.get(\"standard_name\", \"\") or \"\").lower()\n",
    "        longn = (v.attrs.get(\"long_name\", \"\") or \"\").lower()\n",
    "        units = (v.attrs.get(\"units\", \"\") or \"\").lower()\n",
    "        # 简单的启发式判断\n",
    "        if any(k in std for k in [\"latitude\"]) or any(k in longn for k in [\"latitude\"]) or units in (\"degrees_north\", \"degree_north\"):\n",
    "            if \"lat\" in candidates[0]:  # 粗略判断是否在找 lat\n",
    "                return var\n",
    "        if any(k in std for k in [\"longitude\"]) or any(k in longn for k in [\"longitude\"]) or units in (\"degrees_east\", \"degree_east\"):\n",
    "            if \"lon\" in candidates[0]:  # 粗略判断是否在找 lon\n",
    "                return var\n",
    "    return None\n",
    "\n",
    "def get_basic_info(path: Path) -> dict:\n",
    "    \"\"\"\n",
    "    打开 NetCDF 并提取基本信息:\n",
    "      - lat / lon 名称与形状\n",
    "      - time 名称、长度与范围\n",
    "    使用新 API：decode_times=CFDatetimeCoder(use_cftime=True) 以支持 360_day / noleap 等日历。\n",
    "    \"\"\"\n",
    "    info = {}\n",
    "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "\n",
    "    # 使用 with 自动关闭\n",
    "    with xr.open_dataset(path, decode_times=time_coder) as ds:\n",
    "        # 统一小写对比\n",
    "        coord_names_lower = [c.lower() for c in ds.coords]\n",
    "        # 尝试找到 lat / lon / time\n",
    "        lat_candidates = [\"lat\", \"latitude\", \"nav_lat\", \"y\"]\n",
    "        lon_candidates = [\"lon\", \"longitude\", \"nav_lon\", \"x\"]\n",
    "        time_candidates = [\"time\"]\n",
    "\n",
    "        # 转成小写构造候选集\n",
    "        lat_name = _find_coord_name(ds, lat_candidates)\n",
    "        lon_name = _find_coord_name(ds, lon_candidates)\n",
    "\n",
    "        # time 相对固定，直接找\n",
    "        time_name = None\n",
    "        for c in ds.coords:\n",
    "            if c.lower() in time_candidates or \"time\" in c.lower():\n",
    "                time_name = c\n",
    "                break\n",
    "\n",
    "        # 填写 info\n",
    "        if lat_name is not None and lat_name in ds:\n",
    "            info[\"lat_name\"] = lat_name\n",
    "            info[\"lat_shape\"] = tuple(ds[lat_name].shape)\n",
    "        else:\n",
    "            info[\"lat_name\"] = None\n",
    "            info[\"lat_shape\"] = None\n",
    "\n",
    "        if lon_name is not None and lon_name in ds:\n",
    "            info[\"lon_name\"] = lon_name\n",
    "            info[\"lon_shape\"] = tuple(ds[lon_name].shape)\n",
    "        else:\n",
    "            info[\"lon_name\"] = None\n",
    "            info[\"lon_shape\"] = None\n",
    "\n",
    "        if time_name is not None and time_name in ds:\n",
    "            t = ds[time_name]\n",
    "            info[\"time_name\"] = time_name\n",
    "            info[\"time_len\"] = int(t.size)\n",
    "            info[\"time_range\"] = _first_last_as_str(t)\n",
    "        else:\n",
    "            info[\"time_name\"] = None\n",
    "            info[\"time_len\"] = 0\n",
    "            info[\"time_range\"] = \"(not found)\"\n",
    "\n",
    "    return info\n",
    "\n",
    "def main():\n",
    "    print(\"=== 基本信息检查开始 ===\")\n",
    "    base = Path(DATA_DIR)\n",
    "    for fname in FILES:\n",
    "        path = base / fname\n",
    "        if not path.exists():\n",
    "            print(f\"[缺失] {fname}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            info = get_basic_info(path)\n",
    "            print(f\"\\n文件: {fname}\")\n",
    "            print(f\"  lat:  {info.get('lat_name')}    shape={info.get('lat_shape')}\")\n",
    "            print(f\"  lon:  {info.get('lon_name')}    shape={info.get('lon_shape')}\")\n",
    "            print(f\"  time: {info.get('time_name')}   len={info.get('time_len')}\")\n",
    "            print(f\"  time_range: {info.get('time_range')}\")\n",
    "        except Exception as e:\n",
    "            print(f\"[错误] 读取 {fname} 失败：{e}\")\n",
    "\n",
    "    print(\"\\n=== 完成 ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "730c654f-c052-4b60-88bb-a9fe7aa73b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[处理] gpp_Lmon_CanESM5_abrupt-4xCO2_185001-200012.nc | lat=lat (64,), lon=lon (128,)\n",
      "[完成] 保存 -> D:\\cangku\\data\\regridded\\gpp_Lmon_CanESM5_abrupt-4xCO2_185001-200012_1x1_bilinear.nc\n",
      "\n",
      "[处理] gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc | lat=lat (64,), lon=lon (128,)\n",
      "[完成] 保存 -> D:\\cangku\\data\\regridded\\gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912_1x1_bilinear.nc\n",
      "\n",
      "[处理] gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc | lat=lat (64,), lon=lon (128,)\n",
      "[完成] 保存 -> D:\\cangku\\data\\regridded\\gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912_1x1_bilinear.nc\n",
      "\n",
      "[处理] tos_Omon_CanESM5_abrupt-4xCO2_185001-200012.nc | lat=latitude (291, 360), lon=longitude (291, 360)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 233\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m=== 全部处理结束 ===\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 233\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[1], line 219\u001b[0m, in \u001b[0;36mmain\u001b[1;34m()\u001b[0m\n\u001b[0;32m    217\u001b[0m     out \u001b[38;5;241m=\u001b[39m _regrid_rectilinear(ds, lat_name, lon_name)\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 219\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43m_regrid_curvilinear_scipy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlon_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    221\u001b[0m out_name \u001b[38;5;241m=\u001b[39m in_path\u001b[38;5;241m.\u001b[39mstem \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_1x1_bilinear.nc\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    222\u001b[0m out_path \u001b[38;5;241m=\u001b[39m OUT_DIR \u001b[38;5;241m/\u001b[39m out_name\n",
      "Cell \u001b[1;32mIn[1], line 150\u001b[0m, in \u001b[0;36m_regrid_curvilinear_scipy\u001b[1;34m(ds, lat_name, lon_name)\u001b[0m\n\u001b[0;32m    148\u001b[0m Zi \u001b[38;5;241m=\u001b[39m griddata(P[mask], slice2d\u001b[38;5;241m.\u001b[39mravel()[mask], (GX, GY), method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(Zi)\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m--> 150\u001b[0m     Znn \u001b[38;5;241m=\u001b[39m \u001b[43mgriddata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mslice2d\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mravel\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mGX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mGY\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mnearest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    151\u001b[0m     Zi \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mwhere(np\u001b[38;5;241m.\u001b[39misnan(Zi), Znn, Zi)\n\u001b[0;32m    152\u001b[0m out_data[ti] \u001b[38;5;241m=\u001b[39m Zi\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\research\\lib\\site-packages\\scipy\\interpolate\\_ndgriddata.py:321\u001b[0m, in \u001b[0;36mgriddata\u001b[1;34m(points, values, xi, method, fill_value, rescale)\u001b[0m\n\u001b[0;32m    319\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    320\u001b[0m     ip \u001b[38;5;241m=\u001b[39m NearestNDInterpolator(points, values, rescale\u001b[38;5;241m=\u001b[39mrescale)\n\u001b[1;32m--> 321\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mxi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m method \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlinear\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    323\u001b[0m     ip \u001b[38;5;241m=\u001b[39m LinearNDInterpolator(points, values, fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m    324\u001b[0m                               rescale\u001b[38;5;241m=\u001b[39mrescale)\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\research\\lib\\site-packages\\scipy\\interpolate\\_ndgriddata.py:144\u001b[0m, in \u001b[0;36mNearestNDInterpolator.__call__\u001b[1;34m(self, *args, **query_options)\u001b[0m\n\u001b[0;32m    136\u001b[0m flattened_shape \u001b[38;5;241m=\u001b[39m xi_flat\u001b[38;5;241m.\u001b[39mshape\n\u001b[0;32m    138\u001b[0m \u001b[38;5;66;03m# if distance_upper_bound is set to not be infinite,\u001b[39;00m\n\u001b[0;32m    139\u001b[0m \u001b[38;5;66;03m# then we need to consider the case where cKDtree\u001b[39;00m\n\u001b[0;32m    140\u001b[0m \u001b[38;5;66;03m# does not find any points within distance_upper_bound to return.\u001b[39;00m\n\u001b[0;32m    141\u001b[0m \u001b[38;5;66;03m# It marks those points as having infinte distance, which is what will be used\u001b[39;00m\n\u001b[0;32m    142\u001b[0m \u001b[38;5;66;03m# below to mask the array and return only the points that were deemed\u001b[39;00m\n\u001b[0;32m    143\u001b[0m \u001b[38;5;66;03m# to have a close enough neighbor to return something useful.\u001b[39;00m\n\u001b[1;32m--> 144\u001b[0m dist, i \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtree\u001b[38;5;241m.\u001b[39mquery(xi_flat, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mquery_options)\n\u001b[0;32m    145\u001b[0m valid_mask \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39misfinite(dist)\n\u001b[0;32m    147\u001b[0m \u001b[38;5;66;03m# create a holder interp_values array and fill with nans.\u001b[39;00m\n",
      "File \u001b[1;32m_ckdtree.pyx:833\u001b[0m, in \u001b[0;36mscipy.spatial._ckdtree.cKDTree.query\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mD:\\miniconda\\envs\\research\\lib\\site-packages\\numpy\\_core\\fromnumeric.py:209\u001b[0m, in \u001b[0;36m_reshape_dispatcher\u001b[1;34m(a, newshape, order)\u001b[0m\n\u001b[0;32m    111\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;124;03m    Take elements from an array along an axis.\u001b[39;00m\n\u001b[0;32m    113\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m           [5, 7]])\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m    206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtake\u001b[39m\u001b[38;5;124m'\u001b[39m, indices, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout, mode\u001b[38;5;241m=\u001b[39mmode)\n\u001b[1;32m--> 209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21m_reshape_dispatcher\u001b[39m(a, newshape, order\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    210\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a,)\n\u001b[0;32m    213\u001b[0m \u001b[38;5;66;03m# not deprecated --- copy if necessary, view otherwise\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "将给定 NetCDF 文件线性插值到 1°×1° lon-lat 规则网格（lon: 0..359, lat: -90..89）\n",
    "- 规则网格(1D lat/lon)  → xarray.interp(method=\"linear\")\n",
    "- 曲线网格(2D lat/lon)  → scipy.interpolate.griddata:\n",
    "      1) method=\"linear\" 主插值（线性）\n",
    "      2) 对线性插值 NaN 用 method=\"nearest\" 二次填充（仅填空洞/边界）\n",
    "- 自动识别坐标名；time 用 CFDatetimeCoder(use_cftime=True)\n",
    "- 自动排除 vertices/bnds/bounds 顶点与边界变量，仅对物理量插值（优先白名单 tos/gpp）\n",
    "- 输出到 DATA_DIR/regridded，文件名后缀 _1x1_bilinear.nc\n",
    "\"\"\"\n",
    "\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "\n",
    "# ========== 用户可改区域 ==========\n",
    "DATA_DIR = Path(r\"D:\\cangku\\data\")\n",
    "FILES = [\n",
    "    \"gpp_Lmon_CanESM5_abrupt-4xCO2_185001-200012.nc\",\n",
    "    \"gpp_Lmon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    \"gpp_Lmon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    \"tos_Omon_CanESM5_abrupt-4xCO2_185001-200012.nc\",\n",
    "    \"tos_Omon_CanESM5_G1_r1i1p2f1_gn_185001-194912.nc\",\n",
    "    \"tos_Omon_CanESM5_piControl_r1i1p2f1_gn_185001-194912.nc\",\n",
    "]\n",
    "OUT_DIR = DATA_DIR / \"regridded\"\n",
    "# =================================\n",
    "\n",
    "# 目标网格\n",
    "LON_TGT = np.arange(0.0, 360.0, 1.0, dtype=np.float32)   # 0..359\n",
    "LAT_TGT = np.arange(-90.0, 90.0, 1.0, dtype=np.float32)  # -90..89\n",
    "GX, GY = np.meshgrid(LON_TGT, LAT_TGT)  # (180, 360)\n",
    "\n",
    "# ------------------ 工具函数 ------------------\n",
    "def _normalize_lon_to_0_360(lon):\n",
    "    return (lon % 360).astype(np.float64)\n",
    "\n",
    "def _find_coord_name(ds: xr.Dataset, candidates) -> str | None:\n",
    "    lower_map = {name.lower(): name for name in ds.coords}\n",
    "    for cand in candidates:\n",
    "        if cand in lower_map:\n",
    "            return lower_map[cand]\n",
    "    # 在 data_vars 中按 attrs 识别\n",
    "    for var in list(ds.coords) + list(ds.data_vars):\n",
    "        v = ds[var]\n",
    "        std = (v.attrs.get(\"standard_name\", \"\") or \"\").lower()\n",
    "        longn = (v.attrs.get(\"long_name\", \"\") or \"\").lower()\n",
    "        units = (v.attrs.get(\"units\", \"\") or \"\").lower()\n",
    "        if (\"latitude\" in std) or (\"latitude\" in longn) or (units in (\"degrees_north\", \"degree_north\")):\n",
    "            if any(c.startswith(\"lat\") for c in candidates):\n",
    "                return var\n",
    "        if (\"longitude\" in std) or (\"longitude\" in longn) or (units in (\"degrees_east\", \"degree_east\")):\n",
    "            if any(c.startswith(\"lon\") for c in candidates):\n",
    "                return var\n",
    "    return None\n",
    "\n",
    "def _is_rectilinear(ds: xr.Dataset, lat_name: str, lon_name: str) -> bool:\n",
    "    return (ds[lat_name].ndim == 1) and (ds[lon_name].ndim == 1)\n",
    "\n",
    "def _get_spatial_dims(ds: xr.Dataset, lat_name: str, lon_name: str):\n",
    "    if _is_rectilinear(ds, lat_name, lon_name):\n",
    "        return lat_name, lon_name\n",
    "    lat_dims = ds[lat_name].dims\n",
    "    lon_dims = ds[lon_name].dims\n",
    "    if lat_dims != lon_dims or len(lat_dims) != 2:\n",
    "        raise ValueError(f\"曲线网格 lat/lon 维度不匹配: lat={lat_dims}, lon={lon_dims}\")\n",
    "    return lat_dims  # (y_dim, x_dim)\n",
    "\n",
    "def _select_vars_with_spatial_dims(ds: xr.Dataset, y_dim: str, x_dim: str):\n",
    "    \"\"\"\n",
    "    仅挑选真正需要再网格化的物理量变量：\n",
    "    - 必须含 y_dim/x_dim\n",
    "    - 排除名称或维度含 vertices/vertex/bnds/bounds\n",
    "    - 必须为数值型\n",
    "    \"\"\"\n",
    "    bad_tokens = (\"vertices\", \"vertex\", \"bnds\", \"bounds\")\n",
    "    keep = []\n",
    "    for v in ds.data_vars:\n",
    "        da = ds[v]\n",
    "        dims = da.dims\n",
    "        name_l = v.lower()\n",
    "        if not ((y_dim in dims) and (x_dim in dims)):\n",
    "            continue\n",
    "        if any(tok in name_l for tok in bad_tokens):\n",
    "            continue\n",
    "        if any(any(tok in d.lower() for tok in bad_tokens) for d in dims):\n",
    "            continue\n",
    "        if not np.issubdtype(da.dtype, np.number):\n",
    "            continue\n",
    "        keep.append(v)\n",
    "    return keep\n",
    "\n",
    "def _build_encoding_like(ds_vars):\n",
    "    enc = {}\n",
    "    for v in ds_vars:\n",
    "        enc[v] = {\"zlib\": True, \"complevel\": 4, \"dtype\": \"f4\"}\n",
    "    return enc\n",
    "\n",
    "# ------------------ 规则网格：xarray.interp ------------------\n",
    "def _regrid_rectilinear(ds: xr.Dataset, lat_name: str, lon_name: str) -> xr.Dataset:\n",
    "    # 经度统一到 [0,360)，并排序\n",
    "    lon_new = _normalize_lon_to_0_360(ds[lon_name])\n",
    "    ds = ds.assign_coords({lon_name: lon_new}).sortby(lon_name)\n",
    "\n",
    "    out = ds.interp({lat_name: LAT_TGT, lon_name: LON_TGT}, method=\"linear\")\n",
    "    out = out.rename({lat_name: \"lat\", lon_name: \"lon\"})\n",
    "    out[\"lat\"].attrs.update(dict(standard_name=\"latitude\", long_name=\"Latitude\", units=\"degrees_north\"))\n",
    "    out[\"lon\"].attrs.update(dict(standard_name=\"longitude\", long_name=\"Longitude\", units=\"degrees_east\"))\n",
    "    return out\n",
    "\n",
    "# ------------------ 曲线网格：scipy.griddata ------------------\n",
    "def _regrid_curvilinear_scipy(ds: xr.Dataset, lat_name: str, lon_name: str) -> xr.Dataset:\n",
    "    from scipy.interpolate import griddata  # 仅在需要时导入\n",
    "\n",
    "    y_dim, x_dim = _get_spatial_dims(ds, lat_name, lon_name)\n",
    "\n",
    "    lon2d = _normalize_lon_to_0_360(ds[lon_name].astype(np.float64))\n",
    "    lat2d = ds[lat_name].astype(np.float64)\n",
    "\n",
    "    # 输入点坐标 (N, 2)\n",
    "    P = np.column_stack([lon2d.values.ravel(), lat2d.values.ravel()])\n",
    "\n",
    "    # 优先白名单（若存在），否则按筛选规则自动选\n",
    "    preferred = [v for v in ds.data_vars if v.lower() in (\"tos\", \"gpp\")]\n",
    "    var_names = preferred if preferred else _select_vars_with_spatial_dims(ds, y_dim, x_dim)\n",
    "    if not var_names:\n",
    "        raise ValueError(\"未找到需要再网格化的物理量变量。\")\n",
    "\n",
    "    out_vars = {}\n",
    "    target_shape = (LAT_TGT.size, LON_TGT.size)\n",
    "\n",
    "    # time 维名（可无）\n",
    "    time_dim = next((c for c in ds.coords if \"time\" in c.lower()), None)\n",
    "\n",
    "    for v in var_names:\n",
    "        da = ds[v]\n",
    "        dims = da.dims\n",
    "\n",
    "        # (time, y, x)\n",
    "        if (time_dim in dims) and (y_dim in dims) and (x_dim in dims) and (len(dims) == 3):\n",
    "            tN = ds.sizes[time_dim]\n",
    "            out_data = np.full((tN, *target_shape), np.nan, dtype=np.float32)\n",
    "            for ti in range(tN):\n",
    "                slice2d = da.isel({time_dim: ti}).values.astype(np.float64)\n",
    "                mask = np.isfinite(slice2d).ravel()\n",
    "                if mask.sum() >= 3:\n",
    "                    Zi = griddata(P[mask], slice2d.ravel()[mask], (GX, GY), method=\"linear\")\n",
    "                    if np.isnan(Zi).any():\n",
    "                        Znn = griddata(P[mask], slice2d.ravel()[mask], (GX, GY), method=\"nearest\")\n",
    "                        Zi = np.where(np.isnan(Zi), Znn, Zi)\n",
    "                    out_data[ti] = Zi.astype(np.float32)\n",
    "\n",
    "            coords = dict(lon=(\"lon\", LON_TGT), lat=(\"lat\", LAT_TGT))\n",
    "            if time_dim in ds.coords:\n",
    "                coords[time_dim] = ds[time_dim]\n",
    "\n",
    "            out_vars[v] = xr.DataArray(\n",
    "                out_data, dims=(time_dim, \"lat\", \"lon\"),\n",
    "                coords=coords, attrs=da.attrs,\n",
    "            )\n",
    "\n",
    "        # (y, x)\n",
    "        elif (y_dim in dims) and (x_dim in dims) and (len(dims) == 2):\n",
    "            slice2d = da.values.astype(np.float64)\n",
    "            mask = np.isfinite(slice2d).ravel()\n",
    "            if mask.sum() >= 3:\n",
    "                Zi = griddata(P[mask], slice2d.ravel()[mask], (GX, GY), method=\"linear\")\n",
    "                if np.isnan(Zi).any():\n",
    "                    Znn = griddata(P[mask], slice2d.ravel()[mask], (GX, GY), method=\"nearest\")\n",
    "                    Zi = np.where(np.isnan(Zi), Znn, Zi)\n",
    "            else:\n",
    "                Zi = np.full(target_shape, np.nan, dtype=np.float32)\n",
    "\n",
    "            out_vars[v] = xr.DataArray(\n",
    "                Zi.astype(np.float32),\n",
    "                dims=(\"lat\", \"lon\"),\n",
    "                coords=dict(lon=(\"lon\", LON_TGT), lat=(\"lat\", LAT_TGT)),\n",
    "                attrs=da.attrs,\n",
    "            )\n",
    "\n",
    "        else:\n",
    "            print(f\"[跳过] 变量 {v} 维度 {dims} 暂不支持（仅支持 (time,y,x) 或 (y,x)）\")\n",
    "\n",
    "    out = xr.Dataset(out_vars)\n",
    "    out[\"lat\"].attrs.update(dict(standard_name=\"latitude\", long_name=\"Latitude\", units=\"degrees_north\"))\n",
    "    out[\"lon\"].attrs.update(dict(standard_name=\"longitude\", long_name=\"Longitude\", units=\"degrees_east\"))\n",
    "\n",
    "    # 复制 time 等其它坐标\n",
    "    for c in ds.coords:\n",
    "        if c not in (lat_name, lon_name, \"lat\", \"lon\") and c not in out.coords and c in ds:\n",
    "            out = out.assign_coords({c: ds[c]})\n",
    "\n",
    "    return out\n",
    "\n",
    "# ------------------ 主流程 ------------------\n",
    "def main():\n",
    "    OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    time_coder = xr.coders.CFDatetimeCoder(use_cftime=True)\n",
    "\n",
    "    for fname in FILES:\n",
    "        in_path = DATA_DIR / fname\n",
    "        if not in_path.exists():\n",
    "            print(f\"[缺失] {fname}\")\n",
    "            continue\n",
    "\n",
    "        try:\n",
    "            with xr.open_dataset(in_path, decode_times=time_coder) as ds:\n",
    "                lat_name = _find_coord_name(ds, [\"lat\", \"latitude\", \"nav_lat\", \"y\"])\n",
    "                lon_name = _find_coord_name(ds, [\"lon\", \"longitude\", \"nav_lon\", \"x\"])\n",
    "                if (lat_name is None) or (lon_name is None):\n",
    "                    raise ValueError(f\"未找到经纬度坐标：lat={lat_name}, lon={lon_name}\")\n",
    "\n",
    "                print(f\"\\n[处理] {fname} | lat={lat_name} {ds[lat_name].shape}, lon={lon_name} {ds[lon_name].shape}\")\n",
    "\n",
    "                if _is_rectilinear(ds, lat_name, lon_name):\n",
    "                    out = _regrid_rectilinear(ds, lat_name, lon_name)\n",
    "                else:\n",
    "                    out = _regrid_curvilinear_scipy(ds, lat_name, lon_name)\n",
    "\n",
    "                out_name = in_path.stem + \"_1x1_bilinear.nc\"\n",
    "                out_path = OUT_DIR / out_name\n",
    "                enc = _build_encoding_like(out.data_vars)\n",
    "                out.to_netcdf(out_path, format=\"NETCDF4\", encoding=enc)\n",
    "                print(f\"[完成] 保存 -> {out_path}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"[错误] {fname}: {e}\")\n",
    "\n",
    "    print(\"\\n=== 全部处理结束 ===\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ea72d303-0346-4989-9153-216a25e625cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c50595b-f200-4a7d-805a-c913fb38a14a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: D:\\cangku\\data\\GPP.npy (3, 180, 360, 1200) D:\\cangku\\data\\TOS.npy (3, 180, 360, 1200)\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167170a1-6662-43fc-a771-d8ed2e36f480",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54db30c-a3d2-4fee-b17c-122cbf441a52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c0c64d3-1fdb-4f0e-b32c-459d6153702d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631ba59d-1b30-4be4-b1fc-797b1084e9df",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
